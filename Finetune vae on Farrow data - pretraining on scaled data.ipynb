{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from vmf_batch import vMF\n",
    "\n",
    "from models import SeqEncoder, SeqDecoder, Seq2Seq_VAE, PoolingClassifier, init_weights\n",
    "from training_utils import train, evaluate\n",
    "\n",
    "## plotting ###\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 17\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/Farrow_data/iterator/soma_centered/train_iterator.pkl', 'rb') as f:\n",
    "    train_iterator = pickle.load(f)\n",
    "\n",
    "with open('./data/Farrow_data/iterator/soma_centered/val_iterator.pkl', 'rb') as f:\n",
    "    val_iterator = pickle.load(f)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data, trg_data, seq_len, indices, labels = list(train_iterator)[0]\n",
    "bs, n_walks, walk_length, output_dim = src_data.shape\n",
    "\n",
    "N_train = len(train_iterator.sampler.indices)\n",
    "N_val = len(val_iterator.sampler.indices)\n",
    "\n",
    " \n",
    "MASKING_ELEMENT = train_iterator.dataset.masking_el\n",
    "\n",
    "# get number of labels, ignore -100 index\n",
    "l = list(np.unique(labels))\n",
    "if -100 in l:\n",
    "    l.remove(-100)\n",
    "NUM_CLASSES = len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-100,    0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "         10,   11,   12,   13])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_iterator.dataset.labels[train_iterator.sampler.indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD: 45.709938049316406\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 32\n",
    "latent_dim = 32\n",
    "NUM_LAYERS = 2\n",
    "dpout = .1\n",
    "kap = 500\n",
    "pool = 'max'\n",
    "lr = 0.01\n",
    "\n",
    "enc = SeqEncoder(output_dim, emb_dim, emb_dim, NUM_LAYERS, dpout)\n",
    "dec = SeqDecoder(output_dim, emb_dim, emb_dim, NUM_LAYERS, dpout)\n",
    "dist = vMF(latent_dim, kappa=kap)\n",
    "model = Seq2Seq_VAE(enc, dec, dist, device).to(device)\n",
    "classifier = PoolingClassifier(latent_dim, NUM_CLASSES, n_walks,dpout,pooling=pool).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(x, reconstructed_x, ignore_el=MASKING_ELEMENT):\n",
    "    # reconstruction loss\n",
    "    # x = [trg len, batch size * n walks, output dim]\n",
    "\n",
    "    seq_len , bs, output_dim = x.shape\n",
    "    mask = x[:,:,0] != ignore_el\n",
    "    RCL = 0\n",
    "    for d in range(output_dim):\n",
    "        RCL += mse_loss(reconstructed_x[:,:,d][mask], x[:,:,d][mask])\n",
    "    RCL /= output_dim\n",
    "    \n",
    "    return RCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 66.38, Val Loss: 347.67, Time elapsed [s]: 30.63\n",
      "Epoch 1, Train Loss: 66.06, Val Loss: 358.56, Time elapsed [s]: 30.08\n",
      "Epoch 2, Train Loss: 67.52, Val Loss: 353.34, Time elapsed [s]: 27.68\n",
      "Epoch 3, Train Loss: 67.41, Val Loss: 348.22, Time elapsed [s]: 28.83\n",
      "Epoch 4, Train Loss: 66.77, Val Loss: 351.59, Time elapsed [s]: 28.17\n",
      "Epoch 5, Train Loss: 64.86, Val Loss: 346.78, Time elapsed [s]: 27.72\n",
      "Epoch 6, Train Loss: 65.28, Val Loss: 350.25, Time elapsed [s]: 27.81\n",
      "Epoch 7, Train Loss: 65.94, Val Loss: 356.68, Time elapsed [s]: 29.04\n",
      "Epoch 8, Train Loss: 66.53, Val Loss: 355.86, Time elapsed [s]: 28.55\n",
      "Epoch 9, Train Loss: 65.22, Val Loss: 360.28, Time elapsed [s]: 27.86\n",
      "Epoch 10, Train Loss: 65.11, Val Loss: 356.75, Time elapsed [s]: 28.03\n",
      "Epoch 11, Train Loss: 65.73, Val Loss: 344.46, Time elapsed [s]: 28.32\n",
      "Epoch 12, Train Loss: 63.38, Val Loss: 348.33, Time elapsed [s]: 28.10\n",
      "Epoch 13, Train Loss: 65.68, Val Loss: 361.25, Time elapsed [s]: 27.22\n",
      "Epoch 14, Train Loss: 67.37, Val Loss: 340.28, Time elapsed [s]: 27.61\n",
      "Epoch 15, Train Loss: 65.27, Val Loss: 327.27, Time elapsed [s]: 27.36\n",
      "Epoch 16, Train Loss: 63.36, Val Loss: 344.07, Time elapsed [s]: 27.86\n",
      "Epoch 17, Train Loss: 61.86, Val Loss: 348.15, Time elapsed [s]: 28.26\n",
      "Epoch 18, Train Loss: 64.14, Val Loss: 371.91, Time elapsed [s]: 27.70\n",
      "Epoch 19, Train Loss: 61.81, Val Loss: 359.73, Time elapsed [s]: 28.02\n",
      "Epoch 20, Train Loss: 62.40, Val Loss: 344.38, Time elapsed [s]: 27.62\n",
      "Epoch 21, Train Loss: 62.57, Val Loss: 346.82, Time elapsed [s]: 27.46\n",
      "Epoch 22, Train Loss: 62.62, Val Loss: 339.87, Time elapsed [s]: 27.95\n",
      "Epoch 23, Train Loss: 64.75, Val Loss: 358.50, Time elapsed [s]: 27.39\n",
      "Epoch 24, Train Loss: 63.15, Val Loss: 352.55, Time elapsed [s]: 27.69\n",
      "Epoch 25, Train Loss: 62.67, Val Loss: 346.72, Time elapsed [s]: 27.92\n",
      "Epoch 26, Train Loss: 65.00, Val Loss: 352.08, Time elapsed [s]: 27.31\n",
      "Epoch 27, Train Loss: 63.30, Val Loss: 343.08, Time elapsed [s]: 27.28\n",
      "Epoch 28, Train Loss: 64.66, Val Loss: 342.21, Time elapsed [s]: 27.36\n",
      "Epoch 29, Train Loss: 61.76, Val Loss: 347.14, Time elapsed [s]: 27.32\n",
      "Epoch 30, Train Loss: 62.89, Val Loss: 357.92, Time elapsed [s]: 27.51\n",
      "Epoch 31, Train Loss: 62.20, Val Loss: 360.93, Time elapsed [s]: 27.80\n",
      "Epoch 32, Train Loss: 63.35, Val Loss: 355.55, Time elapsed [s]: 27.41\n",
      "Epoch 33, Train Loss: 61.67, Val Loss: 359.82, Time elapsed [s]: 27.21\n",
      "Epoch 34, Train Loss: 61.21, Val Loss: 364.17, Time elapsed [s]: 27.87\n",
      "Epoch 35, Train Loss: 62.83, Val Loss: 360.76, Time elapsed [s]: 28.63\n",
      "Epoch 36, Train Loss: 62.36, Val Loss: 358.06, Time elapsed [s]: 27.94\n",
      "Epoch 37, Train Loss: 61.75, Val Loss: 371.80, Time elapsed [s]: 28.28\n",
      "Epoch 38, Train Loss: 63.81, Val Loss: 362.38, Time elapsed [s]: 28.44\n",
      "Epoch 39, Train Loss: 61.70, Val Loss: 358.82, Time elapsed [s]: 27.67\n",
      "Epoch 40, Train Loss: 63.02, Val Loss: 369.02, Time elapsed [s]: 27.21\n",
      "Epoch 41, Train Loss: 63.69, Val Loss: 372.89, Time elapsed [s]: 27.27\n",
      "Epoch 42, Train Loss: 62.42, Val Loss: 354.99, Time elapsed [s]: 27.73\n",
      "Epoch 43, Train Loss: 60.11, Val Loss: 358.23, Time elapsed [s]: 27.35\n",
      "Epoch 44, Train Loss: 61.19, Val Loss: 351.37, Time elapsed [s]: 28.52\n",
      "Epoch 45, Train Loss: 59.82, Val Loss: 365.23, Time elapsed [s]: 27.63\n",
      "Epoch 46, Train Loss: 60.08, Val Loss: 357.46, Time elapsed [s]: 27.42\n",
      "Epoch 47, Train Loss: 61.41, Val Loss: 354.89, Time elapsed [s]: 27.58\n",
      "Epoch 48, Train Loss: 61.08, Val Loss: 347.29, Time elapsed [s]: 27.32\n",
      "Epoch 49, Train Loss: 59.94, Val Loss: 350.25, Time elapsed [s]: 27.76\n",
      "Epoch 0, Train Loss: 66.07, Val Loss: 386.66, Time elapsed [s]: 28.04\n",
      "Epoch 1, Train Loss: 66.43, Val Loss: 368.63, Time elapsed [s]: 28.16\n",
      "Epoch 2, Train Loss: 65.83, Val Loss: 377.08, Time elapsed [s]: 27.19\n",
      "Epoch 3, Train Loss: 65.04, Val Loss: 373.55, Time elapsed [s]: 27.23\n",
      "Epoch 4, Train Loss: 64.83, Val Loss: 379.08, Time elapsed [s]: 27.36\n",
      "Epoch 5, Train Loss: 66.29, Val Loss: 362.64, Time elapsed [s]: 27.34\n",
      "Epoch 6, Train Loss: 65.41, Val Loss: 379.46, Time elapsed [s]: 27.15\n",
      "Epoch 7, Train Loss: 66.83, Val Loss: 362.36, Time elapsed [s]: 27.20\n",
      "Epoch 8, Train Loss: 63.18, Val Loss: 373.75, Time elapsed [s]: 27.52\n",
      "Epoch 9, Train Loss: 66.46, Val Loss: 383.54, Time elapsed [s]: 27.16\n",
      "Epoch 10, Train Loss: 66.34, Val Loss: 402.84, Time elapsed [s]: 27.10\n",
      "Epoch 11, Train Loss: 65.19, Val Loss: 380.93, Time elapsed [s]: 27.48\n",
      "Epoch 12, Train Loss: 67.80, Val Loss: 385.51, Time elapsed [s]: 27.88\n",
      "Epoch 13, Train Loss: 67.56, Val Loss: 367.85, Time elapsed [s]: 27.55\n",
      "Epoch 14, Train Loss: 64.53, Val Loss: 363.48, Time elapsed [s]: 27.14\n",
      "Epoch 15, Train Loss: 65.06, Val Loss: 363.41, Time elapsed [s]: 27.13\n",
      "Epoch 16, Train Loss: 64.42, Val Loss: 371.22, Time elapsed [s]: 27.32\n",
      "Epoch 17, Train Loss: 65.60, Val Loss: 369.35, Time elapsed [s]: 27.31\n",
      "Epoch 18, Train Loss: 64.86, Val Loss: 362.90, Time elapsed [s]: 27.14\n",
      "Epoch 19, Train Loss: 63.04, Val Loss: 368.60, Time elapsed [s]: 27.03\n",
      "Epoch 20, Train Loss: 63.24, Val Loss: 370.74, Time elapsed [s]: 27.03\n",
      "Epoch 21, Train Loss: 62.72, Val Loss: 371.99, Time elapsed [s]: 27.17\n",
      "Epoch 22, Train Loss: 61.60, Val Loss: 357.09, Time elapsed [s]: 27.19\n",
      "Epoch 23, Train Loss: 61.92, Val Loss: 377.50, Time elapsed [s]: 27.02\n",
      "Epoch 24, Train Loss: 64.19, Val Loss: 362.80, Time elapsed [s]: 26.97\n",
      "Epoch 25, Train Loss: 62.66, Val Loss: 363.64, Time elapsed [s]: 27.08\n",
      "Epoch 26, Train Loss: 62.44, Val Loss: 375.16, Time elapsed [s]: 27.66\n",
      "Epoch 27, Train Loss: 61.84, Val Loss: 360.18, Time elapsed [s]: 27.52\n",
      "Epoch 28, Train Loss: 60.83, Val Loss: 346.60, Time elapsed [s]: 27.33\n",
      "Epoch 29, Train Loss: 61.07, Val Loss: 368.26, Time elapsed [s]: 27.60\n",
      "Epoch 30, Train Loss: 65.04, Val Loss: 367.78, Time elapsed [s]: 27.27\n",
      "Epoch 31, Train Loss: 60.02, Val Loss: 359.22, Time elapsed [s]: 27.24\n",
      "Epoch 32, Train Loss: 59.21, Val Loss: 383.08, Time elapsed [s]: 26.98\n",
      "Epoch 33, Train Loss: 59.84, Val Loss: 377.21, Time elapsed [s]: 27.10\n",
      "Epoch 34, Train Loss: 60.71, Val Loss: 376.93, Time elapsed [s]: 27.25\n",
      "Epoch 35, Train Loss: 60.54, Val Loss: 364.04, Time elapsed [s]: 27.78\n",
      "Epoch 36, Train Loss: 59.85, Val Loss: 378.20, Time elapsed [s]: 27.65\n",
      "Epoch 37, Train Loss: 61.88, Val Loss: 374.86, Time elapsed [s]: 27.97\n",
      "Epoch 38, Train Loss: 60.47, Val Loss: 390.10, Time elapsed [s]: 28.07\n",
      "Epoch 39, Train Loss: 60.35, Val Loss: 375.06, Time elapsed [s]: 27.07\n",
      "Epoch 40, Train Loss: 59.96, Val Loss: 369.96, Time elapsed [s]: 27.08\n",
      "Epoch 41, Train Loss: 58.66, Val Loss: 378.78, Time elapsed [s]: 26.96\n",
      "Epoch 42, Train Loss: 59.82, Val Loss: 380.37, Time elapsed [s]: 27.54\n",
      "Epoch 43, Train Loss: 61.24, Val Loss: 377.04, Time elapsed [s]: 27.33\n",
      "Epoch 44, Train Loss: 61.62, Val Loss: 369.98, Time elapsed [s]: 27.32\n",
      "Epoch 45, Train Loss: 60.32, Val Loss: 387.02, Time elapsed [s]: 27.32\n",
      "Epoch 46, Train Loss: 58.09, Val Loss: 362.31, Time elapsed [s]: 27.40\n",
      "Epoch 47, Train Loss: 57.88, Val Loss: 374.54, Time elapsed [s]: 27.07\n",
      "Epoch 48, Train Loss: 59.17, Val Loss: 378.99, Time elapsed [s]: 27.09\n",
      "Epoch 49, Train Loss: 60.42, Val Loss: 384.88, Time elapsed [s]: 27.06\n",
      "Epoch 0, Train Loss: 70.97, Val Loss: 394.83, Time elapsed [s]: 27.26\n",
      "Epoch 1, Train Loss: 74.77, Val Loss: 382.91, Time elapsed [s]: 27.24\n",
      "Epoch 2, Train Loss: 75.50, Val Loss: 374.67, Time elapsed [s]: 27.20\n",
      "Epoch 3, Train Loss: 72.57, Val Loss: 373.70, Time elapsed [s]: 27.64\n",
      "Epoch 4, Train Loss: 70.50, Val Loss: 372.43, Time elapsed [s]: 27.73\n",
      "Epoch 5, Train Loss: 69.62, Val Loss: 382.42, Time elapsed [s]: 27.53\n",
      "Epoch 6, Train Loss: 69.09, Val Loss: 383.13, Time elapsed [s]: 27.56\n",
      "Epoch 7, Train Loss: 72.36, Val Loss: 376.83, Time elapsed [s]: 27.53\n",
      "Epoch 8, Train Loss: 69.91, Val Loss: 371.38, Time elapsed [s]: 27.54\n",
      "Epoch 9, Train Loss: 69.52, Val Loss: 374.02, Time elapsed [s]: 27.30\n",
      "Epoch 10, Train Loss: 69.69, Val Loss: 380.33, Time elapsed [s]: 27.09\n",
      "Epoch 11, Train Loss: 68.56, Val Loss: 393.20, Time elapsed [s]: 27.25\n",
      "Epoch 12, Train Loss: 69.65, Val Loss: 381.86, Time elapsed [s]: 27.25\n",
      "Epoch 13, Train Loss: 68.97, Val Loss: 359.59, Time elapsed [s]: 27.27\n",
      "Epoch 14, Train Loss: 71.66, Val Loss: 368.54, Time elapsed [s]: 27.22\n",
      "Epoch 15, Train Loss: 72.93, Val Loss: 377.24, Time elapsed [s]: 27.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 70.27, Val Loss: 361.84, Time elapsed [s]: 27.14\n",
      "Epoch 17, Train Loss: 70.33, Val Loss: 365.05, Time elapsed [s]: 27.58\n",
      "Epoch 18, Train Loss: 70.68, Val Loss: 376.38, Time elapsed [s]: 27.36\n",
      "Epoch 19, Train Loss: 69.21, Val Loss: 359.93, Time elapsed [s]: 27.32\n",
      "Epoch 20, Train Loss: 69.86, Val Loss: 360.38, Time elapsed [s]: 27.30\n",
      "Epoch 21, Train Loss: 69.66, Val Loss: 381.84, Time elapsed [s]: 27.35\n",
      "Epoch 22, Train Loss: 69.11, Val Loss: 360.03, Time elapsed [s]: 27.86\n",
      "Epoch 23, Train Loss: 69.27, Val Loss: 360.67, Time elapsed [s]: 28.10\n",
      "Epoch 24, Train Loss: 67.13, Val Loss: 364.45, Time elapsed [s]: 27.30\n",
      "Epoch 25, Train Loss: 69.12, Val Loss: 347.23, Time elapsed [s]: 27.25\n",
      "Epoch 26, Train Loss: 68.94, Val Loss: 368.30, Time elapsed [s]: 27.54\n",
      "Epoch 27, Train Loss: 66.38, Val Loss: 364.29, Time elapsed [s]: 27.41\n",
      "Epoch 28, Train Loss: 67.05, Val Loss: 360.25, Time elapsed [s]: 27.10\n",
      "Epoch 29, Train Loss: 64.74, Val Loss: 373.57, Time elapsed [s]: 27.21\n",
      "Epoch 30, Train Loss: 66.58, Val Loss: 356.73, Time elapsed [s]: 27.58\n",
      "Epoch 31, Train Loss: 67.67, Val Loss: 354.58, Time elapsed [s]: 27.22\n",
      "Epoch 32, Train Loss: 70.02, Val Loss: 375.87, Time elapsed [s]: 27.36\n",
      "Epoch 33, Train Loss: 69.01, Val Loss: 389.03, Time elapsed [s]: 27.33\n",
      "Epoch 34, Train Loss: 71.29, Val Loss: 375.18, Time elapsed [s]: 27.23\n",
      "Epoch 35, Train Loss: 68.66, Val Loss: 357.40, Time elapsed [s]: 27.50\n",
      "Epoch 36, Train Loss: 67.65, Val Loss: 373.27, Time elapsed [s]: 27.60\n",
      "Epoch 37, Train Loss: 68.00, Val Loss: 374.87, Time elapsed [s]: 27.27\n",
      "Epoch 38, Train Loss: 67.28, Val Loss: 352.62, Time elapsed [s]: 27.07\n",
      "Epoch 39, Train Loss: 66.79, Val Loss: 359.33, Time elapsed [s]: 27.21\n",
      "Epoch 40, Train Loss: 65.98, Val Loss: 367.67, Time elapsed [s]: 27.19\n",
      "Epoch 41, Train Loss: 67.31, Val Loss: 361.32, Time elapsed [s]: 27.31\n",
      "Epoch 42, Train Loss: 65.17, Val Loss: 360.78, Time elapsed [s]: 28.42\n",
      "Epoch 43, Train Loss: 67.45, Val Loss: 368.25, Time elapsed [s]: 27.20\n",
      "Epoch 44, Train Loss: 67.11, Val Loss: 360.66, Time elapsed [s]: 27.41\n",
      "Epoch 45, Train Loss: 66.20, Val Loss: 364.28, Time elapsed [s]: 27.56\n",
      "Epoch 46, Train Loss: 65.48, Val Loss: 360.39, Time elapsed [s]: 27.18\n",
      "Epoch 47, Train Loss: 66.73, Val Loss: 360.21, Time elapsed [s]: 27.18\n",
      "Epoch 48, Train Loss: 65.62, Val Loss: 355.36, Time elapsed [s]: 27.17\n",
      "Epoch 49, Train Loss: 64.94, Val Loss: 361.92, Time elapsed [s]: 27.29\n",
      "Epoch 0, Train Loss: 67.87, Val Loss: 383.08, Time elapsed [s]: 30.63\n",
      "Epoch 1, Train Loss: 68.16, Val Loss: 386.93, Time elapsed [s]: 30.08\n",
      "Epoch 2, Train Loss: 69.22, Val Loss: 372.84, Time elapsed [s]: 27.68\n",
      "Epoch 3, Train Loss: 69.39, Val Loss: 394.60, Time elapsed [s]: 28.83\n",
      "Epoch 4, Train Loss: 69.75, Val Loss: 398.51, Time elapsed [s]: 28.17\n",
      "Epoch 5, Train Loss: 70.04, Val Loss: 397.15, Time elapsed [s]: 27.72\n",
      "Epoch 6, Train Loss: 69.34, Val Loss: 391.49, Time elapsed [s]: 27.81\n",
      "Epoch 7, Train Loss: 66.38, Val Loss: 394.23, Time elapsed [s]: 29.04\n",
      "Epoch 8, Train Loss: 70.26, Val Loss: 394.06, Time elapsed [s]: 28.55\n",
      "Epoch 9, Train Loss: 68.25, Val Loss: 377.51, Time elapsed [s]: 27.86\n",
      "Epoch 10, Train Loss: 67.60, Val Loss: 366.17, Time elapsed [s]: 28.03\n",
      "Epoch 11, Train Loss: 66.52, Val Loss: 387.01, Time elapsed [s]: 28.32\n",
      "Epoch 12, Train Loss: 69.05, Val Loss: 406.31, Time elapsed [s]: 28.10\n",
      "Epoch 13, Train Loss: 71.01, Val Loss: 390.55, Time elapsed [s]: 27.22\n",
      "Epoch 14, Train Loss: 66.92, Val Loss: 380.00, Time elapsed [s]: 27.61\n",
      "Epoch 15, Train Loss: 66.19, Val Loss: 374.75, Time elapsed [s]: 27.36\n",
      "Epoch 16, Train Loss: 65.96, Val Loss: 364.18, Time elapsed [s]: 27.86\n",
      "Epoch 17, Train Loss: 65.17, Val Loss: 383.57, Time elapsed [s]: 28.26\n",
      "Epoch 18, Train Loss: 64.50, Val Loss: 384.35, Time elapsed [s]: 27.70\n",
      "Epoch 19, Train Loss: 64.34, Val Loss: 403.04, Time elapsed [s]: 28.02\n",
      "Epoch 20, Train Loss: 65.63, Val Loss: 389.12, Time elapsed [s]: 27.62\n",
      "Epoch 21, Train Loss: 65.03, Val Loss: 404.19, Time elapsed [s]: 27.46\n",
      "Epoch 22, Train Loss: 64.64, Val Loss: 404.11, Time elapsed [s]: 27.95\n",
      "Epoch 23, Train Loss: 63.86, Val Loss: 369.59, Time elapsed [s]: 27.39\n",
      "Epoch 24, Train Loss: 63.23, Val Loss: 377.28, Time elapsed [s]: 27.69\n",
      "Epoch 25, Train Loss: 64.46, Val Loss: 372.60, Time elapsed [s]: 27.92\n",
      "Epoch 26, Train Loss: 63.73, Val Loss: 367.64, Time elapsed [s]: 27.31\n",
      "Epoch 27, Train Loss: 64.33, Val Loss: 378.83, Time elapsed [s]: 27.28\n",
      "Epoch 28, Train Loss: 62.75, Val Loss: 398.86, Time elapsed [s]: 27.36\n",
      "Epoch 29, Train Loss: 62.33, Val Loss: 396.22, Time elapsed [s]: 27.32\n",
      "Epoch 30, Train Loss: 64.44, Val Loss: 390.86, Time elapsed [s]: 27.51\n",
      "Epoch 31, Train Loss: 63.48, Val Loss: 382.39, Time elapsed [s]: 27.80\n",
      "Epoch 32, Train Loss: 63.29, Val Loss: 399.08, Time elapsed [s]: 27.41\n",
      "Epoch 33, Train Loss: 62.08, Val Loss: 414.17, Time elapsed [s]: 27.21\n",
      "Epoch 34, Train Loss: 65.03, Val Loss: 356.63, Time elapsed [s]: 27.87\n",
      "Epoch 35, Train Loss: 63.21, Val Loss: 358.40, Time elapsed [s]: 28.63\n",
      "Epoch 36, Train Loss: 60.24, Val Loss: 358.22, Time elapsed [s]: 27.94\n",
      "Epoch 37, Train Loss: 63.86, Val Loss: 371.53, Time elapsed [s]: 28.28\n",
      "Epoch 38, Train Loss: 61.17, Val Loss: 373.34, Time elapsed [s]: 28.44\n",
      "Epoch 39, Train Loss: 62.14, Val Loss: 382.28, Time elapsed [s]: 27.67\n",
      "Epoch 40, Train Loss: 60.64, Val Loss: 382.86, Time elapsed [s]: 27.21\n",
      "Epoch 41, Train Loss: 63.61, Val Loss: 358.44, Time elapsed [s]: 27.27\n",
      "Epoch 42, Train Loss: 61.10, Val Loss: 367.11, Time elapsed [s]: 27.73\n",
      "Epoch 43, Train Loss: 62.91, Val Loss: 376.72, Time elapsed [s]: 27.35\n",
      "Epoch 44, Train Loss: 63.34, Val Loss: 366.47, Time elapsed [s]: 28.52\n",
      "Epoch 45, Train Loss: 60.70, Val Loss: 368.33, Time elapsed [s]: 27.63\n",
      "Epoch 46, Train Loss: 63.41, Val Loss: 374.70, Time elapsed [s]: 27.42\n",
      "Epoch 47, Train Loss: 58.97, Val Loss: 364.55, Time elapsed [s]: 27.58\n",
      "Epoch 48, Train Loss: 60.62, Val Loss: 358.98, Time elapsed [s]: 27.32\n",
      "Epoch 49, Train Loss: 60.44, Val Loss: 353.76, Time elapsed [s]: 27.76\n",
      "Epoch 0, Train Loss: 64.34, Val Loss: 378.68, Time elapsed [s]: 28.04\n",
      "Epoch 1, Train Loss: 63.30, Val Loss: 394.44, Time elapsed [s]: 28.16\n",
      "Epoch 2, Train Loss: 64.66, Val Loss: 361.62, Time elapsed [s]: 27.19\n",
      "Epoch 3, Train Loss: 62.78, Val Loss: 368.69, Time elapsed [s]: 27.23\n",
      "Epoch 4, Train Loss: 60.89, Val Loss: 356.93, Time elapsed [s]: 27.36\n",
      "Epoch 5, Train Loss: 62.05, Val Loss: 365.82, Time elapsed [s]: 27.34\n",
      "Epoch 6, Train Loss: 62.89, Val Loss: 359.50, Time elapsed [s]: 27.15\n",
      "Epoch 7, Train Loss: 62.13, Val Loss: 364.46, Time elapsed [s]: 27.20\n",
      "Epoch 8, Train Loss: 62.20, Val Loss: 355.77, Time elapsed [s]: 27.52\n",
      "Epoch 9, Train Loss: 61.19, Val Loss: 369.25, Time elapsed [s]: 27.16\n",
      "Epoch 10, Train Loss: 60.83, Val Loss: 348.61, Time elapsed [s]: 27.10\n",
      "Epoch 11, Train Loss: 61.57, Val Loss: 371.01, Time elapsed [s]: 27.48\n",
      "Epoch 12, Train Loss: 60.89, Val Loss: 364.34, Time elapsed [s]: 27.88\n",
      "Epoch 13, Train Loss: 62.53, Val Loss: 351.43, Time elapsed [s]: 27.55\n",
      "Epoch 14, Train Loss: 60.40, Val Loss: 356.39, Time elapsed [s]: 27.14\n",
      "Epoch 15, Train Loss: 59.71, Val Loss: 377.59, Time elapsed [s]: 27.13\n",
      "Epoch 16, Train Loss: 61.22, Val Loss: 363.74, Time elapsed [s]: 27.32\n",
      "Epoch 17, Train Loss: 59.00, Val Loss: 363.55, Time elapsed [s]: 27.31\n",
      "Epoch 18, Train Loss: 60.66, Val Loss: 371.45, Time elapsed [s]: 27.14\n",
      "Epoch 19, Train Loss: 58.58, Val Loss: 366.08, Time elapsed [s]: 27.03\n",
      "Epoch 20, Train Loss: 60.07, Val Loss: 364.05, Time elapsed [s]: 27.03\n",
      "Epoch 21, Train Loss: 59.66, Val Loss: 380.60, Time elapsed [s]: 27.17\n",
      "Epoch 22, Train Loss: 59.50, Val Loss: 352.15, Time elapsed [s]: 27.19\n",
      "Epoch 23, Train Loss: 59.86, Val Loss: 360.75, Time elapsed [s]: 27.02\n",
      "Epoch 24, Train Loss: 57.89, Val Loss: 362.09, Time elapsed [s]: 26.97\n",
      "Epoch 25, Train Loss: 59.25, Val Loss: 383.62, Time elapsed [s]: 27.08\n",
      "Epoch 26, Train Loss: 60.47, Val Loss: 366.79, Time elapsed [s]: 27.66\n",
      "Epoch 27, Train Loss: 57.22, Val Loss: 337.83, Time elapsed [s]: 27.52\n",
      "Epoch 28, Train Loss: 58.46, Val Loss: 368.68, Time elapsed [s]: 27.33\n",
      "Epoch 29, Train Loss: 60.85, Val Loss: 403.66, Time elapsed [s]: 27.60\n",
      "Epoch 30, Train Loss: 67.90, Val Loss: 371.87, Time elapsed [s]: 27.27\n",
      "Epoch 31, Train Loss: 60.06, Val Loss: 365.22, Time elapsed [s]: 27.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Train Loss: 59.37, Val Loss: 361.61, Time elapsed [s]: 26.98\n",
      "Epoch 33, Train Loss: 58.58, Val Loss: 365.70, Time elapsed [s]: 27.10\n",
      "Epoch 34, Train Loss: 56.13, Val Loss: 352.72, Time elapsed [s]: 27.25\n",
      "Epoch 35, Train Loss: 55.97, Val Loss: 378.07, Time elapsed [s]: 27.78\n",
      "Epoch 36, Train Loss: 58.44, Val Loss: 381.28, Time elapsed [s]: 27.65\n",
      "Epoch 37, Train Loss: 57.95, Val Loss: 389.20, Time elapsed [s]: 27.97\n",
      "Epoch 38, Train Loss: 57.41, Val Loss: 381.92, Time elapsed [s]: 28.07\n",
      "Epoch 39, Train Loss: 56.80, Val Loss: 372.65, Time elapsed [s]: 27.07\n",
      "Epoch 40, Train Loss: 56.14, Val Loss: 385.80, Time elapsed [s]: 27.08\n",
      "Epoch 41, Train Loss: 58.84, Val Loss: 365.11, Time elapsed [s]: 26.96\n",
      "Epoch 42, Train Loss: 58.60, Val Loss: 361.29, Time elapsed [s]: 27.54\n",
      "Epoch 43, Train Loss: 59.55, Val Loss: 376.22, Time elapsed [s]: 27.33\n",
      "Epoch 44, Train Loss: 57.29, Val Loss: 377.79, Time elapsed [s]: 27.32\n",
      "Epoch 45, Train Loss: 56.19, Val Loss: 365.51, Time elapsed [s]: 27.32\n",
      "Epoch 46, Train Loss: 56.11, Val Loss: 362.36, Time elapsed [s]: 27.40\n",
      "Epoch 47, Train Loss: 55.52, Val Loss: 356.83, Time elapsed [s]: 27.07\n",
      "Epoch 48, Train Loss: 55.43, Val Loss: 370.17, Time elapsed [s]: 27.09\n",
      "Epoch 49, Train Loss: 56.19, Val Loss: 385.99, Time elapsed [s]: 27.06\n",
      "Epoch 0, Train Loss: 61.98, Val Loss: 388.34, Time elapsed [s]: 27.26\n",
      "Epoch 1, Train Loss: 63.28, Val Loss: 374.64, Time elapsed [s]: 27.24\n",
      "Epoch 2, Train Loss: 63.36, Val Loss: 376.64, Time elapsed [s]: 27.20\n",
      "Epoch 3, Train Loss: 63.24, Val Loss: 365.11, Time elapsed [s]: 27.64\n",
      "Epoch 4, Train Loss: 62.31, Val Loss: 379.13, Time elapsed [s]: 27.73\n",
      "Epoch 5, Train Loss: 61.73, Val Loss: 375.47, Time elapsed [s]: 27.53\n",
      "Epoch 6, Train Loss: 63.66, Val Loss: 387.83, Time elapsed [s]: 27.56\n",
      "Epoch 7, Train Loss: 62.23, Val Loss: 369.87, Time elapsed [s]: 27.53\n",
      "Epoch 8, Train Loss: 61.42, Val Loss: 374.23, Time elapsed [s]: 27.54\n",
      "Epoch 9, Train Loss: 61.76, Val Loss: 381.99, Time elapsed [s]: 27.30\n",
      "Epoch 10, Train Loss: 62.80, Val Loss: 367.20, Time elapsed [s]: 27.09\n",
      "Epoch 11, Train Loss: 60.95, Val Loss: 372.40, Time elapsed [s]: 27.25\n",
      "Epoch 12, Train Loss: 61.88, Val Loss: 390.02, Time elapsed [s]: 27.25\n",
      "Epoch 13, Train Loss: 60.24, Val Loss: 371.07, Time elapsed [s]: 27.27\n",
      "Epoch 14, Train Loss: 60.87, Val Loss: 371.94, Time elapsed [s]: 27.22\n",
      "Epoch 15, Train Loss: 60.54, Val Loss: 372.62, Time elapsed [s]: 27.12\n",
      "Epoch 16, Train Loss: 60.24, Val Loss: 370.81, Time elapsed [s]: 27.14\n",
      "Epoch 17, Train Loss: 59.72, Val Loss: 362.60, Time elapsed [s]: 27.58\n",
      "Epoch 18, Train Loss: 58.86, Val Loss: 361.42, Time elapsed [s]: 27.36\n",
      "Epoch 19, Train Loss: 59.14, Val Loss: 382.38, Time elapsed [s]: 27.32\n",
      "Epoch 20, Train Loss: 59.11, Val Loss: 367.68, Time elapsed [s]: 27.30\n",
      "Epoch 21, Train Loss: 58.23, Val Loss: 364.10, Time elapsed [s]: 27.35\n",
      "Epoch 22, Train Loss: 56.95, Val Loss: 355.79, Time elapsed [s]: 27.86\n",
      "Epoch 23, Train Loss: 59.45, Val Loss: 371.81, Time elapsed [s]: 28.10\n",
      "Epoch 24, Train Loss: 61.26, Val Loss: 370.75, Time elapsed [s]: 27.30\n",
      "Epoch 25, Train Loss: 61.03, Val Loss: 359.31, Time elapsed [s]: 27.25\n",
      "Epoch 26, Train Loss: 60.39, Val Loss: 356.84, Time elapsed [s]: 27.54\n",
      "Epoch 27, Train Loss: 58.79, Val Loss: 380.12, Time elapsed [s]: 27.41\n",
      "Epoch 28, Train Loss: 61.60, Val Loss: 367.69, Time elapsed [s]: 27.10\n",
      "Epoch 29, Train Loss: 60.78, Val Loss: 382.07, Time elapsed [s]: 27.21\n",
      "Epoch 30, Train Loss: 60.55, Val Loss: 368.15, Time elapsed [s]: 27.58\n",
      "Epoch 31, Train Loss: 61.33, Val Loss: 366.88, Time elapsed [s]: 27.22\n",
      "Epoch 32, Train Loss: 59.83, Val Loss: 369.23, Time elapsed [s]: 27.36\n",
      "Epoch 33, Train Loss: 58.51, Val Loss: 366.23, Time elapsed [s]: 27.33\n",
      "Epoch 34, Train Loss: 58.78, Val Loss: 358.53, Time elapsed [s]: 27.23\n",
      "Epoch 35, Train Loss: 60.33, Val Loss: 346.18, Time elapsed [s]: 27.50\n",
      "Epoch 36, Train Loss: 58.92, Val Loss: 361.79, Time elapsed [s]: 27.60\n",
      "Epoch 37, Train Loss: 57.77, Val Loss: 370.45, Time elapsed [s]: 27.27\n",
      "Epoch 38, Train Loss: 56.56, Val Loss: 377.85, Time elapsed [s]: 27.07\n",
      "Epoch 39, Train Loss: 59.15, Val Loss: 369.59, Time elapsed [s]: 27.21\n",
      "Epoch 40, Train Loss: 57.38, Val Loss: 375.07, Time elapsed [s]: 27.19\n",
      "Epoch 41, Train Loss: 59.38, Val Loss: 373.99, Time elapsed [s]: 27.31\n",
      "Epoch 42, Train Loss: 58.24, Val Loss: 352.03, Time elapsed [s]: 28.42\n",
      "Epoch 43, Train Loss: 55.83, Val Loss: 378.68, Time elapsed [s]: 27.20\n",
      "Epoch 44, Train Loss: 55.87, Val Loss: 368.33, Time elapsed [s]: 27.41\n",
      "Epoch 45, Train Loss: 56.37, Val Loss: 369.51, Time elapsed [s]: 27.56\n",
      "Epoch 46, Train Loss: 57.12, Val Loss: 387.62, Time elapsed [s]: 27.18\n",
      "Epoch 47, Train Loss: 56.26, Val Loss: 377.86, Time elapsed [s]: 27.18\n",
      "Epoch 48, Train Loss: 56.90, Val Loss: 364.26, Time elapsed [s]: 27.17\n",
      "Epoch 49, Train Loss: 56.31, Val Loss: 371.29, Time elapsed [s]: 27.29\n",
      "Epoch 0, Train Loss: 47.19, Val Loss: 369.55, Time elapsed [s]: 30.63\n",
      "Epoch 1, Train Loss: 46.88, Val Loss: 360.45, Time elapsed [s]: 30.08\n",
      "Epoch 2, Train Loss: 46.64, Val Loss: 360.40, Time elapsed [s]: 27.68\n",
      "Epoch 3, Train Loss: 48.86, Val Loss: 373.18, Time elapsed [s]: 28.83\n",
      "Epoch 4, Train Loss: 47.79, Val Loss: 375.00, Time elapsed [s]: 28.17\n",
      "Epoch 5, Train Loss: 47.59, Val Loss: 365.21, Time elapsed [s]: 27.72\n",
      "Epoch 6, Train Loss: 47.16, Val Loss: 378.52, Time elapsed [s]: 27.81\n",
      "Epoch 7, Train Loss: 47.65, Val Loss: 384.78, Time elapsed [s]: 29.04\n",
      "Epoch 8, Train Loss: 46.91, Val Loss: 358.89, Time elapsed [s]: 28.55\n",
      "Epoch 9, Train Loss: 46.86, Val Loss: 365.67, Time elapsed [s]: 27.86\n",
      "Epoch 10, Train Loss: 46.68, Val Loss: 365.03, Time elapsed [s]: 28.03\n",
      "Epoch 11, Train Loss: 44.61, Val Loss: 370.03, Time elapsed [s]: 28.32\n",
      "Epoch 12, Train Loss: 43.02, Val Loss: 374.12, Time elapsed [s]: 28.10\n",
      "Epoch 13, Train Loss: 47.10, Val Loss: 370.19, Time elapsed [s]: 27.22\n",
      "Epoch 14, Train Loss: 46.38, Val Loss: 372.60, Time elapsed [s]: 27.61\n",
      "Epoch 15, Train Loss: 46.96, Val Loss: 364.49, Time elapsed [s]: 27.36\n",
      "Epoch 16, Train Loss: 45.46, Val Loss: 353.11, Time elapsed [s]: 27.86\n",
      "Epoch 17, Train Loss: 43.76, Val Loss: 358.48, Time elapsed [s]: 28.26\n",
      "Epoch 18, Train Loss: 47.97, Val Loss: 361.50, Time elapsed [s]: 27.70\n",
      "Epoch 19, Train Loss: 44.36, Val Loss: 365.65, Time elapsed [s]: 28.02\n",
      "Epoch 20, Train Loss: 45.66, Val Loss: 360.84, Time elapsed [s]: 27.62\n",
      "Epoch 21, Train Loss: 48.49, Val Loss: 356.83, Time elapsed [s]: 27.46\n",
      "Epoch 22, Train Loss: 45.70, Val Loss: 366.00, Time elapsed [s]: 27.95\n",
      "Epoch 23, Train Loss: 45.31, Val Loss: 359.35, Time elapsed [s]: 27.39\n",
      "Epoch 24, Train Loss: 43.83, Val Loss: 362.01, Time elapsed [s]: 27.69\n",
      "Epoch 25, Train Loss: 45.38, Val Loss: 369.80, Time elapsed [s]: 27.92\n",
      "Epoch 26, Train Loss: 45.89, Val Loss: 356.99, Time elapsed [s]: 27.31\n",
      "Epoch 27, Train Loss: 46.00, Val Loss: 357.98, Time elapsed [s]: 27.28\n",
      "Epoch 28, Train Loss: 44.34, Val Loss: 369.04, Time elapsed [s]: 27.36\n",
      "Epoch 29, Train Loss: 45.69, Val Loss: 388.62, Time elapsed [s]: 27.32\n",
      "Epoch 30, Train Loss: 44.26, Val Loss: 375.84, Time elapsed [s]: 27.51\n",
      "Epoch 31, Train Loss: 44.01, Val Loss: 365.36, Time elapsed [s]: 27.80\n",
      "Epoch 32, Train Loss: 43.83, Val Loss: 347.22, Time elapsed [s]: 27.41\n",
      "Epoch 33, Train Loss: 46.19, Val Loss: 351.03, Time elapsed [s]: 27.21\n",
      "Epoch 34, Train Loss: 45.46, Val Loss: 354.41, Time elapsed [s]: 27.87\n",
      "Epoch 35, Train Loss: 45.39, Val Loss: 343.02, Time elapsed [s]: 28.63\n",
      "Epoch 36, Train Loss: 44.41, Val Loss: 345.72, Time elapsed [s]: 27.94\n",
      "Epoch 37, Train Loss: 44.56, Val Loss: 366.30, Time elapsed [s]: 28.28\n",
      "Epoch 38, Train Loss: 46.09, Val Loss: 371.82, Time elapsed [s]: 28.44\n",
      "Epoch 39, Train Loss: 46.64, Val Loss: 368.76, Time elapsed [s]: 27.67\n",
      "Epoch 40, Train Loss: 44.22, Val Loss: 349.63, Time elapsed [s]: 27.21\n",
      "Epoch 41, Train Loss: 47.07, Val Loss: 353.84, Time elapsed [s]: 27.27\n",
      "Epoch 42, Train Loss: 45.53, Val Loss: 367.18, Time elapsed [s]: 27.73\n",
      "Epoch 43, Train Loss: 45.31, Val Loss: 350.43, Time elapsed [s]: 27.35\n",
      "Epoch 44, Train Loss: 44.67, Val Loss: 361.62, Time elapsed [s]: 28.52\n",
      "Epoch 45, Train Loss: 40.59, Val Loss: 373.18, Time elapsed [s]: 27.63\n",
      "Epoch 46, Train Loss: 42.81, Val Loss: 364.43, Time elapsed [s]: 27.42\n",
      "Epoch 47, Train Loss: 41.96, Val Loss: 374.08, Time elapsed [s]: 27.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Train Loss: 45.44, Val Loss: 347.04, Time elapsed [s]: 27.32\n",
      "Epoch 49, Train Loss: 43.09, Val Loss: 375.26, Time elapsed [s]: 27.76\n",
      "Epoch 0, Train Loss: 47.71, Val Loss: 367.17, Time elapsed [s]: 28.04\n",
      "Epoch 1, Train Loss: 49.58, Val Loss: 377.67, Time elapsed [s]: 28.16\n",
      "Epoch 2, Train Loss: 49.60, Val Loss: 355.90, Time elapsed [s]: 27.19\n",
      "Epoch 3, Train Loss: 48.98, Val Loss: 362.25, Time elapsed [s]: 27.23\n",
      "Epoch 4, Train Loss: 49.19, Val Loss: 355.11, Time elapsed [s]: 27.36\n",
      "Epoch 5, Train Loss: 45.77, Val Loss: 370.36, Time elapsed [s]: 27.34\n",
      "Epoch 6, Train Loss: 48.63, Val Loss: 363.93, Time elapsed [s]: 27.15\n",
      "Epoch 7, Train Loss: 46.85, Val Loss: 369.92, Time elapsed [s]: 27.20\n",
      "Epoch 8, Train Loss: 47.97, Val Loss: 360.07, Time elapsed [s]: 27.52\n",
      "Epoch 9, Train Loss: 48.40, Val Loss: 368.01, Time elapsed [s]: 27.16\n",
      "Epoch 10, Train Loss: 48.42, Val Loss: 383.61, Time elapsed [s]: 27.10\n",
      "Epoch 11, Train Loss: 48.76, Val Loss: 367.54, Time elapsed [s]: 27.48\n",
      "Epoch 12, Train Loss: 47.40, Val Loss: 369.61, Time elapsed [s]: 27.88\n",
      "Epoch 13, Train Loss: 46.91, Val Loss: 375.66, Time elapsed [s]: 27.55\n",
      "Epoch 14, Train Loss: 46.61, Val Loss: 350.70, Time elapsed [s]: 27.14\n",
      "Epoch 15, Train Loss: 48.18, Val Loss: 363.78, Time elapsed [s]: 27.13\n",
      "Epoch 16, Train Loss: 47.51, Val Loss: 368.67, Time elapsed [s]: 27.32\n",
      "Epoch 17, Train Loss: 44.08, Val Loss: 362.01, Time elapsed [s]: 27.31\n",
      "Epoch 18, Train Loss: 43.68, Val Loss: 374.93, Time elapsed [s]: 27.14\n",
      "Epoch 19, Train Loss: 43.72, Val Loss: 362.06, Time elapsed [s]: 27.03\n",
      "Epoch 20, Train Loss: 47.32, Val Loss: 371.25, Time elapsed [s]: 27.03\n",
      "Epoch 21, Train Loss: 46.05, Val Loss: 368.81, Time elapsed [s]: 27.17\n",
      "Epoch 22, Train Loss: 50.48, Val Loss: 367.96, Time elapsed [s]: 27.19\n",
      "Epoch 23, Train Loss: 46.28, Val Loss: 364.64, Time elapsed [s]: 27.02\n",
      "Epoch 24, Train Loss: 47.35, Val Loss: 363.36, Time elapsed [s]: 26.97\n",
      "Epoch 25, Train Loss: 46.48, Val Loss: 364.27, Time elapsed [s]: 27.08\n",
      "Epoch 26, Train Loss: 47.37, Val Loss: 372.51, Time elapsed [s]: 27.66\n",
      "Epoch 27, Train Loss: 48.05, Val Loss: 354.47, Time elapsed [s]: 27.52\n",
      "Epoch 28, Train Loss: 46.43, Val Loss: 364.04, Time elapsed [s]: 27.33\n",
      "Epoch 29, Train Loss: 48.54, Val Loss: 374.22, Time elapsed [s]: 27.60\n",
      "Epoch 30, Train Loss: 47.55, Val Loss: 357.61, Time elapsed [s]: 27.27\n",
      "Epoch 31, Train Loss: 46.56, Val Loss: 372.32, Time elapsed [s]: 27.24\n",
      "Epoch 32, Train Loss: 48.27, Val Loss: 374.23, Time elapsed [s]: 26.98\n",
      "Epoch 33, Train Loss: 47.23, Val Loss: 367.70, Time elapsed [s]: 27.10\n",
      "Epoch 34, Train Loss: 45.14, Val Loss: 362.77, Time elapsed [s]: 27.25\n",
      "Epoch 35, Train Loss: 46.18, Val Loss: 363.22, Time elapsed [s]: 27.78\n",
      "Epoch 36, Train Loss: 46.08, Val Loss: 371.29, Time elapsed [s]: 27.65\n",
      "Epoch 37, Train Loss: 43.71, Val Loss: 357.03, Time elapsed [s]: 27.97\n",
      "Epoch 38, Train Loss: 48.16, Val Loss: 357.05, Time elapsed [s]: 28.07\n",
      "Epoch 39, Train Loss: 45.89, Val Loss: 358.37, Time elapsed [s]: 27.07\n",
      "Epoch 40, Train Loss: 46.89, Val Loss: 359.39, Time elapsed [s]: 27.08\n",
      "Epoch 41, Train Loss: 46.56, Val Loss: 360.51, Time elapsed [s]: 26.96\n",
      "Epoch 42, Train Loss: 46.75, Val Loss: 354.79, Time elapsed [s]: 27.54\n",
      "Epoch 43, Train Loss: 46.18, Val Loss: 363.55, Time elapsed [s]: 27.33\n",
      "Epoch 44, Train Loss: 46.71, Val Loss: 367.10, Time elapsed [s]: 27.32\n",
      "Epoch 45, Train Loss: 45.22, Val Loss: 359.52, Time elapsed [s]: 27.32\n",
      "Epoch 46, Train Loss: 44.30, Val Loss: 365.93, Time elapsed [s]: 27.40\n",
      "Epoch 47, Train Loss: 44.42, Val Loss: 367.15, Time elapsed [s]: 27.07\n",
      "Epoch 48, Train Loss: 45.52, Val Loss: 353.16, Time elapsed [s]: 27.09\n",
      "Epoch 49, Train Loss: 44.09, Val Loss: 368.05, Time elapsed [s]: 27.06\n",
      "Epoch 0, Train Loss: 46.56, Val Loss: 377.10, Time elapsed [s]: 27.26\n",
      "Epoch 1, Train Loss: 49.84, Val Loss: 369.49, Time elapsed [s]: 27.24\n",
      "Epoch 2, Train Loss: 46.13, Val Loss: 365.39, Time elapsed [s]: 27.20\n",
      "Epoch 3, Train Loss: 49.41, Val Loss: 370.71, Time elapsed [s]: 27.64\n",
      "Epoch 4, Train Loss: 46.24, Val Loss: 386.58, Time elapsed [s]: 27.73\n",
      "Epoch 5, Train Loss: 45.93, Val Loss: 368.03, Time elapsed [s]: 27.53\n",
      "Epoch 6, Train Loss: 46.75, Val Loss: 375.04, Time elapsed [s]: 27.56\n",
      "Epoch 7, Train Loss: 46.27, Val Loss: 360.77, Time elapsed [s]: 27.53\n",
      "Epoch 8, Train Loss: 45.73, Val Loss: 355.01, Time elapsed [s]: 27.54\n",
      "Epoch 9, Train Loss: 48.11, Val Loss: 363.63, Time elapsed [s]: 27.30\n",
      "Epoch 10, Train Loss: 46.89, Val Loss: 353.10, Time elapsed [s]: 27.09\n",
      "Epoch 11, Train Loss: 46.90, Val Loss: 357.09, Time elapsed [s]: 27.25\n",
      "Epoch 12, Train Loss: 46.18, Val Loss: 362.00, Time elapsed [s]: 27.25\n",
      "Epoch 13, Train Loss: 46.75, Val Loss: 361.39, Time elapsed [s]: 27.27\n",
      "Epoch 14, Train Loss: 46.15, Val Loss: 346.32, Time elapsed [s]: 27.22\n",
      "Epoch 15, Train Loss: 46.70, Val Loss: 369.17, Time elapsed [s]: 27.12\n",
      "Epoch 16, Train Loss: 46.95, Val Loss: 354.41, Time elapsed [s]: 27.14\n",
      "Epoch 17, Train Loss: 44.60, Val Loss: 362.06, Time elapsed [s]: 27.58\n",
      "Epoch 18, Train Loss: 46.24, Val Loss: 362.51, Time elapsed [s]: 27.36\n",
      "Epoch 19, Train Loss: 48.75, Val Loss: 359.95, Time elapsed [s]: 27.32\n",
      "Epoch 20, Train Loss: 44.98, Val Loss: 356.94, Time elapsed [s]: 27.30\n",
      "Epoch 21, Train Loss: 46.81, Val Loss: 356.62, Time elapsed [s]: 27.35\n",
      "Epoch 22, Train Loss: 45.61, Val Loss: 361.59, Time elapsed [s]: 27.86\n",
      "Epoch 23, Train Loss: 49.46, Val Loss: 361.89, Time elapsed [s]: 28.10\n",
      "Epoch 24, Train Loss: 46.70, Val Loss: 358.13, Time elapsed [s]: 27.30\n",
      "Epoch 25, Train Loss: 44.35, Val Loss: 363.08, Time elapsed [s]: 27.25\n",
      "Epoch 26, Train Loss: 45.23, Val Loss: 368.37, Time elapsed [s]: 27.54\n",
      "Epoch 27, Train Loss: 45.87, Val Loss: 375.09, Time elapsed [s]: 27.41\n",
      "Epoch 28, Train Loss: 45.60, Val Loss: 367.09, Time elapsed [s]: 27.10\n",
      "Epoch 29, Train Loss: 46.74, Val Loss: 364.38, Time elapsed [s]: 27.21\n",
      "Epoch 30, Train Loss: 44.11, Val Loss: 352.08, Time elapsed [s]: 27.58\n",
      "Epoch 31, Train Loss: 44.09, Val Loss: 359.23, Time elapsed [s]: 27.22\n",
      "Epoch 32, Train Loss: 42.52, Val Loss: 365.95, Time elapsed [s]: 27.36\n",
      "Epoch 33, Train Loss: 44.27, Val Loss: 365.77, Time elapsed [s]: 27.33\n",
      "Epoch 34, Train Loss: 44.78, Val Loss: 355.98, Time elapsed [s]: 27.23\n",
      "Epoch 35, Train Loss: 45.20, Val Loss: 352.36, Time elapsed [s]: 27.50\n",
      "Epoch 36, Train Loss: 46.91, Val Loss: 348.26, Time elapsed [s]: 27.60\n",
      "Epoch 37, Train Loss: 46.10, Val Loss: 352.80, Time elapsed [s]: 27.27\n",
      "Epoch 38, Train Loss: 41.67, Val Loss: 363.17, Time elapsed [s]: 27.07\n",
      "Epoch 39, Train Loss: 44.76, Val Loss: 339.97, Time elapsed [s]: 27.21\n",
      "Epoch 40, Train Loss: 42.69, Val Loss: 357.38, Time elapsed [s]: 27.19\n",
      "Epoch 41, Train Loss: 44.26, Val Loss: 340.77, Time elapsed [s]: 27.31\n",
      "Epoch 42, Train Loss: 43.76, Val Loss: 356.18, Time elapsed [s]: 28.42\n",
      "Epoch 43, Train Loss: 41.73, Val Loss: 343.63, Time elapsed [s]: 27.20\n",
      "Epoch 44, Train Loss: 42.86, Val Loss: 339.79, Time elapsed [s]: 27.41\n",
      "Epoch 45, Train Loss: 42.67, Val Loss: 351.81, Time elapsed [s]: 27.56\n",
      "Epoch 46, Train Loss: 42.40, Val Loss: 345.22, Time elapsed [s]: 27.18\n",
      "Epoch 47, Train Loss: 44.71, Val Loss: 355.29, Time elapsed [s]: 27.18\n",
      "Epoch 48, Train Loss: 44.90, Val Loss: 347.81, Time elapsed [s]: 27.17\n",
      "Epoch 49, Train Loss: 45.63, Val Loss: 353.21, Time elapsed [s]: 27.29\n",
      "Epoch 0, Train Loss: 24.29, Val Loss: 447.11, Time elapsed [s]: 30.63\n",
      "Epoch 1, Train Loss: 24.72, Val Loss: 454.97, Time elapsed [s]: 30.08\n",
      "Epoch 2, Train Loss: 24.23, Val Loss: 455.26, Time elapsed [s]: 27.68\n",
      "Epoch 3, Train Loss: 23.36, Val Loss: 448.35, Time elapsed [s]: 28.83\n",
      "Epoch 4, Train Loss: 24.49, Val Loss: 455.95, Time elapsed [s]: 28.17\n",
      "Epoch 5, Train Loss: 25.42, Val Loss: 441.43, Time elapsed [s]: 27.72\n",
      "Epoch 6, Train Loss: 23.17, Val Loss: 449.23, Time elapsed [s]: 27.81\n",
      "Epoch 7, Train Loss: 25.74, Val Loss: 453.95, Time elapsed [s]: 29.04\n",
      "Epoch 8, Train Loss: 24.18, Val Loss: 445.16, Time elapsed [s]: 28.55\n",
      "Epoch 9, Train Loss: 25.50, Val Loss: 453.62, Time elapsed [s]: 27.86\n",
      "Epoch 10, Train Loss: 27.63, Val Loss: 438.01, Time elapsed [s]: 28.03\n",
      "Epoch 11, Train Loss: 26.09, Val Loss: 453.34, Time elapsed [s]: 28.32\n",
      "Epoch 12, Train Loss: 22.42, Val Loss: 437.81, Time elapsed [s]: 28.10\n",
      "Epoch 13, Train Loss: 22.86, Val Loss: 432.08, Time elapsed [s]: 27.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Loss: 24.36, Val Loss: 439.86, Time elapsed [s]: 27.61\n",
      "Epoch 15, Train Loss: 24.28, Val Loss: 433.64, Time elapsed [s]: 27.36\n",
      "Epoch 16, Train Loss: 24.12, Val Loss: 445.24, Time elapsed [s]: 27.86\n",
      "Epoch 17, Train Loss: 23.92, Val Loss: 451.12, Time elapsed [s]: 28.26\n",
      "Epoch 18, Train Loss: 21.76, Val Loss: 439.82, Time elapsed [s]: 27.70\n",
      "Epoch 19, Train Loss: 22.13, Val Loss: 448.01, Time elapsed [s]: 28.02\n",
      "Epoch 20, Train Loss: 23.95, Val Loss: 437.54, Time elapsed [s]: 27.62\n",
      "Epoch 21, Train Loss: 24.94, Val Loss: 455.32, Time elapsed [s]: 27.46\n",
      "Epoch 22, Train Loss: 25.01, Val Loss: 436.96, Time elapsed [s]: 27.95\n",
      "Epoch 23, Train Loss: 21.33, Val Loss: 440.97, Time elapsed [s]: 27.39\n",
      "Epoch 24, Train Loss: 23.66, Val Loss: 431.88, Time elapsed [s]: 27.69\n",
      "Epoch 25, Train Loss: 22.77, Val Loss: 431.86, Time elapsed [s]: 27.92\n",
      "Epoch 26, Train Loss: 22.34, Val Loss: 421.27, Time elapsed [s]: 27.31\n",
      "Epoch 27, Train Loss: 23.68, Val Loss: 440.67, Time elapsed [s]: 27.28\n",
      "Epoch 28, Train Loss: 21.70, Val Loss: 426.96, Time elapsed [s]: 27.36\n",
      "Epoch 29, Train Loss: 24.75, Val Loss: 421.27, Time elapsed [s]: 27.32\n",
      "Epoch 30, Train Loss: 22.70, Val Loss: 424.88, Time elapsed [s]: 27.51\n",
      "Epoch 31, Train Loss: 22.24, Val Loss: 431.04, Time elapsed [s]: 27.80\n",
      "Epoch 32, Train Loss: 24.63, Val Loss: 436.96, Time elapsed [s]: 27.41\n",
      "Epoch 33, Train Loss: 22.49, Val Loss: 438.97, Time elapsed [s]: 27.21\n",
      "Epoch 34, Train Loss: 20.64, Val Loss: 456.98, Time elapsed [s]: 27.87\n",
      "Epoch 35, Train Loss: 23.04, Val Loss: 437.45, Time elapsed [s]: 28.63\n",
      "Epoch 36, Train Loss: 24.39, Val Loss: 426.72, Time elapsed [s]: 27.94\n",
      "Epoch 37, Train Loss: 24.16, Val Loss: 424.81, Time elapsed [s]: 28.28\n",
      "Epoch 38, Train Loss: 22.96, Val Loss: 452.61, Time elapsed [s]: 28.44\n",
      "Epoch 39, Train Loss: 24.38, Val Loss: 427.55, Time elapsed [s]: 27.67\n",
      "Epoch 40, Train Loss: 24.62, Val Loss: 434.35, Time elapsed [s]: 27.21\n",
      "Epoch 41, Train Loss: 21.86, Val Loss: 429.82, Time elapsed [s]: 27.27\n",
      "Epoch 42, Train Loss: 22.66, Val Loss: 424.52, Time elapsed [s]: 27.73\n",
      "Epoch 43, Train Loss: 21.65, Val Loss: 438.06, Time elapsed [s]: 27.35\n",
      "Epoch 44, Train Loss: 22.17, Val Loss: 434.87, Time elapsed [s]: 28.52\n",
      "Epoch 45, Train Loss: 23.65, Val Loss: 440.67, Time elapsed [s]: 27.63\n",
      "Epoch 46, Train Loss: 23.67, Val Loss: 438.51, Time elapsed [s]: 27.42\n",
      "Epoch 47, Train Loss: 21.57, Val Loss: 448.92, Time elapsed [s]: 27.58\n",
      "Epoch 48, Train Loss: 26.06, Val Loss: 435.24, Time elapsed [s]: 27.32\n",
      "Epoch 49, Train Loss: 23.92, Val Loss: 444.23, Time elapsed [s]: 27.76\n",
      "Epoch 0, Train Loss: 24.84, Val Loss: 445.93, Time elapsed [s]: 28.04\n",
      "Epoch 1, Train Loss: 23.01, Val Loss: 437.56, Time elapsed [s]: 28.16\n",
      "Epoch 2, Train Loss: 22.68, Val Loss: 427.96, Time elapsed [s]: 27.19\n",
      "Epoch 3, Train Loss: 22.53, Val Loss: 434.05, Time elapsed [s]: 27.23\n",
      "Epoch 4, Train Loss: 24.91, Val Loss: 456.53, Time elapsed [s]: 27.36\n",
      "Epoch 5, Train Loss: 24.14, Val Loss: 454.21, Time elapsed [s]: 27.34\n",
      "Epoch 6, Train Loss: 23.82, Val Loss: 431.78, Time elapsed [s]: 27.15\n",
      "Epoch 7, Train Loss: 25.54, Val Loss: 446.34, Time elapsed [s]: 27.20\n",
      "Epoch 8, Train Loss: 24.33, Val Loss: 447.26, Time elapsed [s]: 27.52\n",
      "Epoch 9, Train Loss: 23.86, Val Loss: 436.15, Time elapsed [s]: 27.16\n",
      "Epoch 10, Train Loss: 25.70, Val Loss: 437.20, Time elapsed [s]: 27.10\n",
      "Epoch 11, Train Loss: 24.77, Val Loss: 430.22, Time elapsed [s]: 27.48\n",
      "Epoch 12, Train Loss: 24.71, Val Loss: 439.29, Time elapsed [s]: 27.88\n",
      "Epoch 13, Train Loss: 24.29, Val Loss: 434.59, Time elapsed [s]: 27.55\n",
      "Epoch 14, Train Loss: 22.25, Val Loss: 439.46, Time elapsed [s]: 27.14\n",
      "Epoch 15, Train Loss: 23.33, Val Loss: 437.29, Time elapsed [s]: 27.13\n",
      "Epoch 16, Train Loss: 23.34, Val Loss: 424.70, Time elapsed [s]: 27.32\n",
      "Epoch 17, Train Loss: 24.01, Val Loss: 433.77, Time elapsed [s]: 27.31\n",
      "Epoch 18, Train Loss: 25.72, Val Loss: 435.20, Time elapsed [s]: 27.14\n",
      "Epoch 19, Train Loss: 23.22, Val Loss: 424.78, Time elapsed [s]: 27.03\n",
      "Epoch 20, Train Loss: 23.80, Val Loss: 432.50, Time elapsed [s]: 27.03\n",
      "Epoch 21, Train Loss: 21.84, Val Loss: 433.64, Time elapsed [s]: 27.17\n",
      "Epoch 22, Train Loss: 23.08, Val Loss: 435.69, Time elapsed [s]: 27.19\n",
      "Epoch 23, Train Loss: 23.38, Val Loss: 443.98, Time elapsed [s]: 27.02\n",
      "Epoch 24, Train Loss: 23.29, Val Loss: 432.91, Time elapsed [s]: 26.97\n",
      "Epoch 25, Train Loss: 24.29, Val Loss: 442.75, Time elapsed [s]: 27.08\n",
      "Epoch 26, Train Loss: 23.74, Val Loss: 421.01, Time elapsed [s]: 27.66\n",
      "Epoch 27, Train Loss: 25.15, Val Loss: 435.60, Time elapsed [s]: 27.52\n",
      "Epoch 28, Train Loss: 24.51, Val Loss: 433.49, Time elapsed [s]: 27.33\n",
      "Epoch 29, Train Loss: 24.74, Val Loss: 422.75, Time elapsed [s]: 27.60\n",
      "Epoch 30, Train Loss: 25.07, Val Loss: 418.31, Time elapsed [s]: 27.27\n",
      "Epoch 31, Train Loss: 26.57, Val Loss: 443.68, Time elapsed [s]: 27.24\n",
      "Epoch 32, Train Loss: 27.81, Val Loss: 418.95, Time elapsed [s]: 26.98\n",
      "Epoch 33, Train Loss: 23.96, Val Loss: 423.60, Time elapsed [s]: 27.10\n",
      "Epoch 34, Train Loss: 24.75, Val Loss: 437.57, Time elapsed [s]: 27.25\n",
      "Epoch 35, Train Loss: 22.42, Val Loss: 432.33, Time elapsed [s]: 27.78\n",
      "Epoch 36, Train Loss: 28.41, Val Loss: 422.82, Time elapsed [s]: 27.65\n",
      "Epoch 37, Train Loss: 25.72, Val Loss: 430.97, Time elapsed [s]: 27.97\n",
      "Epoch 38, Train Loss: 22.94, Val Loss: 426.24, Time elapsed [s]: 28.07\n",
      "Epoch 39, Train Loss: 23.53, Val Loss: 411.05, Time elapsed [s]: 27.07\n",
      "Epoch 40, Train Loss: 23.84, Val Loss: 418.36, Time elapsed [s]: 27.08\n",
      "Epoch 41, Train Loss: 24.50, Val Loss: 419.74, Time elapsed [s]: 26.96\n",
      "Epoch 42, Train Loss: 25.56, Val Loss: 416.86, Time elapsed [s]: 27.54\n",
      "Epoch 43, Train Loss: 23.69, Val Loss: 433.22, Time elapsed [s]: 27.33\n",
      "Epoch 44, Train Loss: 25.68, Val Loss: 425.50, Time elapsed [s]: 27.32\n",
      "Epoch 45, Train Loss: 23.31, Val Loss: 415.74, Time elapsed [s]: 27.32\n",
      "Epoch 46, Train Loss: 22.97, Val Loss: 423.95, Time elapsed [s]: 27.40\n",
      "Epoch 47, Train Loss: 23.29, Val Loss: 424.25, Time elapsed [s]: 27.07\n",
      "Epoch 48, Train Loss: 23.94, Val Loss: 413.35, Time elapsed [s]: 27.09\n",
      "Epoch 49, Train Loss: 20.93, Val Loss: 425.85, Time elapsed [s]: 27.06\n",
      "Epoch 0, Train Loss: 24.33, Val Loss: 434.48, Time elapsed [s]: 27.26\n",
      "Epoch 1, Train Loss: 25.31, Val Loss: 441.50, Time elapsed [s]: 27.24\n",
      "Epoch 2, Train Loss: 24.13, Val Loss: 442.61, Time elapsed [s]: 27.20\n",
      "Epoch 3, Train Loss: 23.31, Val Loss: 439.85, Time elapsed [s]: 27.64\n",
      "Epoch 4, Train Loss: 25.64, Val Loss: 444.42, Time elapsed [s]: 27.73\n",
      "Epoch 5, Train Loss: 24.14, Val Loss: 453.48, Time elapsed [s]: 27.53\n",
      "Epoch 6, Train Loss: 24.73, Val Loss: 432.61, Time elapsed [s]: 27.56\n",
      "Epoch 7, Train Loss: 23.54, Val Loss: 446.83, Time elapsed [s]: 27.53\n",
      "Epoch 8, Train Loss: 25.22, Val Loss: 439.30, Time elapsed [s]: 27.54\n",
      "Epoch 9, Train Loss: 23.11, Val Loss: 430.58, Time elapsed [s]: 27.30\n",
      "Epoch 10, Train Loss: 26.54, Val Loss: 434.65, Time elapsed [s]: 27.09\n",
      "Epoch 11, Train Loss: 24.32, Val Loss: 450.71, Time elapsed [s]: 27.25\n",
      "Epoch 12, Train Loss: 25.12, Val Loss: 438.59, Time elapsed [s]: 27.25\n",
      "Epoch 13, Train Loss: 24.83, Val Loss: 447.19, Time elapsed [s]: 27.27\n",
      "Epoch 14, Train Loss: 23.77, Val Loss: 448.12, Time elapsed [s]: 27.22\n",
      "Epoch 15, Train Loss: 25.22, Val Loss: 439.74, Time elapsed [s]: 27.12\n",
      "Epoch 16, Train Loss: 23.39, Val Loss: 434.58, Time elapsed [s]: 27.14\n",
      "Epoch 17, Train Loss: 27.05, Val Loss: 439.45, Time elapsed [s]: 27.58\n",
      "Epoch 18, Train Loss: 27.31, Val Loss: 432.83, Time elapsed [s]: 27.36\n",
      "Epoch 19, Train Loss: 25.41, Val Loss: 442.17, Time elapsed [s]: 27.32\n",
      "Epoch 20, Train Loss: 28.73, Val Loss: 430.18, Time elapsed [s]: 27.30\n",
      "Epoch 21, Train Loss: 24.88, Val Loss: 435.93, Time elapsed [s]: 27.35\n",
      "Epoch 22, Train Loss: 25.76, Val Loss: 436.38, Time elapsed [s]: 27.86\n",
      "Epoch 23, Train Loss: 28.56, Val Loss: 443.26, Time elapsed [s]: 28.10\n",
      "Epoch 24, Train Loss: 25.88, Val Loss: 430.76, Time elapsed [s]: 27.30\n",
      "Epoch 25, Train Loss: 24.87, Val Loss: 428.26, Time elapsed [s]: 27.25\n",
      "Epoch 26, Train Loss: 26.32, Val Loss: 426.33, Time elapsed [s]: 27.54\n",
      "Epoch 27, Train Loss: 28.51, Val Loss: 429.26, Time elapsed [s]: 27.41\n",
      "Epoch 28, Train Loss: 25.15, Val Loss: 427.90, Time elapsed [s]: 27.10\n",
      "Epoch 29, Train Loss: 25.92, Val Loss: 443.52, Time elapsed [s]: 27.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train Loss: 28.25, Val Loss: 429.39, Time elapsed [s]: 27.58\n",
      "Epoch 31, Train Loss: 27.96, Val Loss: 452.70, Time elapsed [s]: 27.22\n",
      "Epoch 32, Train Loss: 27.97, Val Loss: 416.07, Time elapsed [s]: 27.36\n",
      "Epoch 33, Train Loss: 24.12, Val Loss: 424.64, Time elapsed [s]: 27.33\n",
      "Epoch 34, Train Loss: 25.55, Val Loss: 427.47, Time elapsed [s]: 27.23\n",
      "Epoch 35, Train Loss: 27.21, Val Loss: 428.84, Time elapsed [s]: 27.50\n",
      "Epoch 36, Train Loss: 24.19, Val Loss: 431.67, Time elapsed [s]: 27.60\n",
      "Epoch 37, Train Loss: 24.47, Val Loss: 430.22, Time elapsed [s]: 27.27\n",
      "Epoch 38, Train Loss: 24.12, Val Loss: 432.87, Time elapsed [s]: 27.07\n",
      "Epoch 39, Train Loss: 23.55, Val Loss: 434.66, Time elapsed [s]: 27.21\n",
      "Epoch 40, Train Loss: 23.75, Val Loss: 444.39, Time elapsed [s]: 27.19\n",
      "Epoch 41, Train Loss: 24.04, Val Loss: 437.81, Time elapsed [s]: 27.31\n",
      "Epoch 42, Train Loss: 25.80, Val Loss: 427.67, Time elapsed [s]: 28.42\n",
      "Epoch 43, Train Loss: 23.37, Val Loss: 433.21, Time elapsed [s]: 27.20\n",
      "Epoch 44, Train Loss: 22.40, Val Loss: 426.94, Time elapsed [s]: 27.41\n",
      "Epoch 45, Train Loss: 22.91, Val Loss: 424.53, Time elapsed [s]: 27.56\n",
      "Epoch 46, Train Loss: 21.26, Val Loss: 425.80, Time elapsed [s]: 27.18\n",
      "Epoch 47, Train Loss: 23.08, Val Loss: 431.03, Time elapsed [s]: 27.18\n",
      "Epoch 48, Train Loss: 24.32, Val Loss: 428.33, Time elapsed [s]: 27.17\n",
      "Epoch 49, Train Loss: 24.21, Val Loss: 423.45, Time elapsed [s]: 27.29\n",
      "Epoch 0, Train Loss: 16.13, Val Loss: 521.50, Time elapsed [s]: 30.63\n",
      "Epoch 1, Train Loss: 15.80, Val Loss: 523.37, Time elapsed [s]: 30.08\n",
      "Epoch 2, Train Loss: 16.19, Val Loss: 534.08, Time elapsed [s]: 27.68\n",
      "Epoch 3, Train Loss: 16.27, Val Loss: 513.11, Time elapsed [s]: 28.83\n",
      "Epoch 4, Train Loss: 15.94, Val Loss: 522.49, Time elapsed [s]: 28.17\n",
      "Epoch 5, Train Loss: 16.22, Val Loss: 524.85, Time elapsed [s]: 27.72\n",
      "Epoch 6, Train Loss: 20.54, Val Loss: 575.37, Time elapsed [s]: 27.81\n",
      "Epoch 7, Train Loss: 18.25, Val Loss: 551.01, Time elapsed [s]: 29.04\n",
      "Epoch 8, Train Loss: 19.26, Val Loss: 534.90, Time elapsed [s]: 28.55\n",
      "Epoch 9, Train Loss: 17.03, Val Loss: 531.57, Time elapsed [s]: 27.86\n",
      "Epoch 10, Train Loss: 16.43, Val Loss: 545.18, Time elapsed [s]: 28.03\n",
      "Epoch 11, Train Loss: 17.37, Val Loss: 533.18, Time elapsed [s]: 28.32\n",
      "Epoch 12, Train Loss: 18.27, Val Loss: 524.51, Time elapsed [s]: 28.10\n",
      "Epoch 13, Train Loss: 17.83, Val Loss: 509.69, Time elapsed [s]: 27.22\n",
      "Epoch 14, Train Loss: 16.59, Val Loss: 517.41, Time elapsed [s]: 27.61\n",
      "Epoch 15, Train Loss: 16.13, Val Loss: 520.46, Time elapsed [s]: 27.36\n",
      "Epoch 16, Train Loss: 18.23, Val Loss: 530.88, Time elapsed [s]: 27.86\n",
      "Epoch 17, Train Loss: 17.58, Val Loss: 521.77, Time elapsed [s]: 28.26\n",
      "Epoch 18, Train Loss: 16.71, Val Loss: 521.32, Time elapsed [s]: 27.70\n",
      "Epoch 19, Train Loss: 15.94, Val Loss: 520.82, Time elapsed [s]: 28.02\n",
      "Epoch 20, Train Loss: 15.43, Val Loss: 517.15, Time elapsed [s]: 27.62\n",
      "Epoch 21, Train Loss: 15.75, Val Loss: 526.01, Time elapsed [s]: 27.46\n",
      "Epoch 22, Train Loss: 15.16, Val Loss: 507.05, Time elapsed [s]: 27.95\n",
      "Epoch 23, Train Loss: 15.12, Val Loss: 517.17, Time elapsed [s]: 27.39\n",
      "Epoch 24, Train Loss: 15.27, Val Loss: 507.95, Time elapsed [s]: 27.69\n",
      "Epoch 25, Train Loss: 14.88, Val Loss: 510.82, Time elapsed [s]: 27.92\n",
      "Epoch 26, Train Loss: 15.51, Val Loss: 506.57, Time elapsed [s]: 27.31\n",
      "Epoch 27, Train Loss: 17.21, Val Loss: 516.52, Time elapsed [s]: 27.28\n",
      "Epoch 28, Train Loss: 16.26, Val Loss: 520.10, Time elapsed [s]: 27.36\n",
      "Epoch 29, Train Loss: 16.47, Val Loss: 518.52, Time elapsed [s]: 27.32\n",
      "Epoch 30, Train Loss: 15.93, Val Loss: 509.72, Time elapsed [s]: 27.51\n",
      "Epoch 31, Train Loss: 17.16, Val Loss: 518.37, Time elapsed [s]: 27.80\n",
      "Epoch 32, Train Loss: 15.62, Val Loss: 511.90, Time elapsed [s]: 27.41\n",
      "Epoch 33, Train Loss: 15.83, Val Loss: 519.76, Time elapsed [s]: 27.21\n",
      "Epoch 34, Train Loss: 17.74, Val Loss: 523.26, Time elapsed [s]: 27.87\n",
      "Epoch 35, Train Loss: 15.67, Val Loss: 511.44, Time elapsed [s]: 28.63\n",
      "Epoch 36, Train Loss: 16.85, Val Loss: 503.54, Time elapsed [s]: 27.94\n",
      "Epoch 37, Train Loss: 14.93, Val Loss: 518.50, Time elapsed [s]: 28.28\n",
      "Epoch 38, Train Loss: 15.37, Val Loss: 536.44, Time elapsed [s]: 28.44\n",
      "Epoch 39, Train Loss: 15.31, Val Loss: 521.05, Time elapsed [s]: 27.67\n",
      "Epoch 40, Train Loss: 15.23, Val Loss: 519.72, Time elapsed [s]: 27.21\n",
      "Epoch 41, Train Loss: 14.77, Val Loss: 505.86, Time elapsed [s]: 27.27\n",
      "Epoch 42, Train Loss: 14.40, Val Loss: 521.38, Time elapsed [s]: 27.73\n",
      "Epoch 43, Train Loss: 14.62, Val Loss: 516.29, Time elapsed [s]: 27.35\n",
      "Epoch 44, Train Loss: 14.35, Val Loss: 517.99, Time elapsed [s]: 28.52\n",
      "Epoch 45, Train Loss: 14.00, Val Loss: 507.55, Time elapsed [s]: 27.63\n",
      "Epoch 46, Train Loss: 14.80, Val Loss: 509.30, Time elapsed [s]: 27.42\n",
      "Epoch 47, Train Loss: 14.41, Val Loss: 506.47, Time elapsed [s]: 27.58\n",
      "Epoch 48, Train Loss: 13.94, Val Loss: 530.78, Time elapsed [s]: 27.32\n",
      "Epoch 49, Train Loss: 14.27, Val Loss: 517.96, Time elapsed [s]: 27.76\n",
      "Epoch 0, Train Loss: 17.39, Val Loss: 519.23, Time elapsed [s]: 28.04\n",
      "Epoch 1, Train Loss: 17.16, Val Loss: 522.55, Time elapsed [s]: 28.16\n",
      "Epoch 2, Train Loss: 16.93, Val Loss: 523.34, Time elapsed [s]: 27.19\n",
      "Epoch 3, Train Loss: 17.34, Val Loss: 529.99, Time elapsed [s]: 27.23\n",
      "Epoch 4, Train Loss: 16.64, Val Loss: 527.29, Time elapsed [s]: 27.36\n",
      "Epoch 5, Train Loss: 16.89, Val Loss: 532.17, Time elapsed [s]: 27.34\n",
      "Epoch 6, Train Loss: 16.80, Val Loss: 526.45, Time elapsed [s]: 27.15\n",
      "Epoch 7, Train Loss: 16.37, Val Loss: 519.25, Time elapsed [s]: 27.20\n",
      "Epoch 8, Train Loss: 16.82, Val Loss: 525.49, Time elapsed [s]: 27.52\n",
      "Epoch 9, Train Loss: 15.96, Val Loss: 521.29, Time elapsed [s]: 27.16\n",
      "Epoch 10, Train Loss: 16.55, Val Loss: 517.97, Time elapsed [s]: 27.10\n",
      "Epoch 11, Train Loss: 15.90, Val Loss: 512.61, Time elapsed [s]: 27.48\n",
      "Epoch 12, Train Loss: 16.42, Val Loss: 526.09, Time elapsed [s]: 27.88\n",
      "Epoch 13, Train Loss: 16.20, Val Loss: 509.38, Time elapsed [s]: 27.55\n",
      "Epoch 14, Train Loss: 15.70, Val Loss: 509.61, Time elapsed [s]: 27.14\n",
      "Epoch 15, Train Loss: 15.60, Val Loss: 513.21, Time elapsed [s]: 27.13\n",
      "Epoch 16, Train Loss: 16.07, Val Loss: 523.01, Time elapsed [s]: 27.32\n",
      "Epoch 17, Train Loss: 15.68, Val Loss: 529.92, Time elapsed [s]: 27.31\n",
      "Epoch 18, Train Loss: 15.87, Val Loss: 515.94, Time elapsed [s]: 27.14\n",
      "Epoch 19, Train Loss: 15.55, Val Loss: 523.26, Time elapsed [s]: 27.03\n",
      "Epoch 20, Train Loss: 15.61, Val Loss: 511.89, Time elapsed [s]: 27.03\n",
      "Epoch 21, Train Loss: 15.40, Val Loss: 521.29, Time elapsed [s]: 27.17\n",
      "Epoch 22, Train Loss: 15.43, Val Loss: 518.98, Time elapsed [s]: 27.19\n",
      "Epoch 23, Train Loss: 15.21, Val Loss: 519.04, Time elapsed [s]: 27.02\n",
      "Epoch 24, Train Loss: 15.35, Val Loss: 523.81, Time elapsed [s]: 26.97\n",
      "Epoch 25, Train Loss: 15.32, Val Loss: 515.31, Time elapsed [s]: 27.08\n",
      "Epoch 26, Train Loss: 15.35, Val Loss: 526.24, Time elapsed [s]: 27.66\n",
      "Epoch 27, Train Loss: 15.64, Val Loss: 519.86, Time elapsed [s]: 27.52\n",
      "Epoch 28, Train Loss: 15.26, Val Loss: 534.64, Time elapsed [s]: 27.33\n",
      "Epoch 29, Train Loss: 14.85, Val Loss: 527.89, Time elapsed [s]: 27.60\n",
      "Epoch 30, Train Loss: 15.38, Val Loss: 520.25, Time elapsed [s]: 27.27\n",
      "Epoch 31, Train Loss: 15.27, Val Loss: 510.23, Time elapsed [s]: 27.24\n",
      "Epoch 32, Train Loss: 15.01, Val Loss: 523.06, Time elapsed [s]: 26.98\n",
      "Epoch 33, Train Loss: 15.55, Val Loss: 518.79, Time elapsed [s]: 27.10\n",
      "Epoch 34, Train Loss: 15.30, Val Loss: 520.97, Time elapsed [s]: 27.25\n",
      "Epoch 35, Train Loss: 15.03, Val Loss: 526.87, Time elapsed [s]: 27.78\n",
      "Epoch 36, Train Loss: 15.17, Val Loss: 505.76, Time elapsed [s]: 27.65\n",
      "Epoch 37, Train Loss: 16.00, Val Loss: 520.58, Time elapsed [s]: 27.97\n",
      "Epoch 38, Train Loss: 16.25, Val Loss: 515.24, Time elapsed [s]: 28.07\n",
      "Epoch 39, Train Loss: 15.95, Val Loss: 522.83, Time elapsed [s]: 27.07\n",
      "Epoch 40, Train Loss: 14.80, Val Loss: 514.79, Time elapsed [s]: 27.08\n",
      "Epoch 41, Train Loss: 15.11, Val Loss: 516.75, Time elapsed [s]: 26.96\n",
      "Epoch 42, Train Loss: 14.75, Val Loss: 521.83, Time elapsed [s]: 27.54\n",
      "Epoch 43, Train Loss: 14.59, Val Loss: 498.69, Time elapsed [s]: 27.33\n",
      "Epoch 44, Train Loss: 14.78, Val Loss: 508.46, Time elapsed [s]: 27.32\n",
      "Epoch 45, Train Loss: 14.26, Val Loss: 513.03, Time elapsed [s]: 27.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Train Loss: 14.77, Val Loss: 528.37, Time elapsed [s]: 27.40\n",
      "Epoch 47, Train Loss: 14.60, Val Loss: 521.76, Time elapsed [s]: 27.07\n",
      "Epoch 48, Train Loss: 14.29, Val Loss: 506.91, Time elapsed [s]: 27.09\n",
      "Epoch 49, Train Loss: 14.47, Val Loss: 509.99, Time elapsed [s]: 27.06\n",
      "Epoch 0, Train Loss: 18.50, Val Loss: 516.59, Time elapsed [s]: 27.26\n",
      "Epoch 1, Train Loss: 18.39, Val Loss: 530.14, Time elapsed [s]: 27.24\n",
      "Epoch 2, Train Loss: 18.03, Val Loss: 530.50, Time elapsed [s]: 27.20\n",
      "Epoch 3, Train Loss: 18.72, Val Loss: 528.83, Time elapsed [s]: 27.64\n",
      "Epoch 4, Train Loss: 18.41, Val Loss: 537.19, Time elapsed [s]: 27.73\n",
      "Epoch 5, Train Loss: 18.79, Val Loss: 525.79, Time elapsed [s]: 27.53\n",
      "Epoch 6, Train Loss: 18.27, Val Loss: 516.42, Time elapsed [s]: 27.56\n",
      "Epoch 7, Train Loss: 18.61, Val Loss: 516.97, Time elapsed [s]: 27.53\n",
      "Epoch 8, Train Loss: 18.05, Val Loss: 544.07, Time elapsed [s]: 27.54\n",
      "Epoch 9, Train Loss: 18.52, Val Loss: 520.96, Time elapsed [s]: 27.30\n",
      "Epoch 10, Train Loss: 18.33, Val Loss: 528.46, Time elapsed [s]: 27.09\n",
      "Epoch 11, Train Loss: 18.18, Val Loss: 536.25, Time elapsed [s]: 27.25\n",
      "Epoch 12, Train Loss: 18.86, Val Loss: 519.86, Time elapsed [s]: 27.25\n",
      "Epoch 13, Train Loss: 18.38, Val Loss: 535.43, Time elapsed [s]: 27.27\n",
      "Epoch 14, Train Loss: 18.71, Val Loss: 520.61, Time elapsed [s]: 27.22\n",
      "Epoch 15, Train Loss: 18.67, Val Loss: 522.91, Time elapsed [s]: 27.12\n",
      "Epoch 16, Train Loss: 18.91, Val Loss: 536.39, Time elapsed [s]: 27.14\n",
      "Epoch 17, Train Loss: 17.64, Val Loss: 527.29, Time elapsed [s]: 27.58\n",
      "Epoch 18, Train Loss: 18.60, Val Loss: 514.94, Time elapsed [s]: 27.36\n",
      "Epoch 19, Train Loss: 17.11, Val Loss: 536.67, Time elapsed [s]: 27.32\n",
      "Epoch 20, Train Loss: 20.24, Val Loss: 519.94, Time elapsed [s]: 27.30\n",
      "Epoch 21, Train Loss: 18.01, Val Loss: 513.31, Time elapsed [s]: 27.35\n",
      "Epoch 22, Train Loss: 18.35, Val Loss: 526.54, Time elapsed [s]: 27.86\n",
      "Epoch 23, Train Loss: 17.52, Val Loss: 534.97, Time elapsed [s]: 28.10\n",
      "Epoch 24, Train Loss: 18.81, Val Loss: 509.28, Time elapsed [s]: 27.30\n",
      "Epoch 25, Train Loss: 18.28, Val Loss: 527.54, Time elapsed [s]: 27.25\n",
      "Epoch 26, Train Loss: 17.82, Val Loss: 525.73, Time elapsed [s]: 27.54\n",
      "Epoch 27, Train Loss: 18.08, Val Loss: 535.46, Time elapsed [s]: 27.41\n",
      "Epoch 28, Train Loss: 17.18, Val Loss: 526.63, Time elapsed [s]: 27.10\n",
      "Epoch 29, Train Loss: 18.55, Val Loss: 525.93, Time elapsed [s]: 27.21\n",
      "Epoch 30, Train Loss: 18.16, Val Loss: 520.58, Time elapsed [s]: 27.58\n",
      "Epoch 31, Train Loss: 18.28, Val Loss: 522.71, Time elapsed [s]: 27.22\n",
      "Epoch 32, Train Loss: 17.92, Val Loss: 525.57, Time elapsed [s]: 27.36\n",
      "Epoch 33, Train Loss: 17.81, Val Loss: 525.71, Time elapsed [s]: 27.33\n",
      "Epoch 34, Train Loss: 16.81, Val Loss: 529.70, Time elapsed [s]: 27.23\n",
      "Epoch 35, Train Loss: 18.90, Val Loss: 517.91, Time elapsed [s]: 27.50\n",
      "Epoch 36, Train Loss: 17.98, Val Loss: 520.66, Time elapsed [s]: 27.60\n",
      "Epoch 37, Train Loss: 17.68, Val Loss: 528.79, Time elapsed [s]: 27.27\n",
      "Epoch 38, Train Loss: 18.19, Val Loss: 526.84, Time elapsed [s]: 27.07\n",
      "Epoch 39, Train Loss: 17.36, Val Loss: 517.49, Time elapsed [s]: 27.21\n",
      "Epoch 40, Train Loss: 17.52, Val Loss: 514.02, Time elapsed [s]: 27.19\n",
      "Epoch 41, Train Loss: 16.69, Val Loss: 525.37, Time elapsed [s]: 27.31\n",
      "Epoch 42, Train Loss: 18.29, Val Loss: 519.66, Time elapsed [s]: 28.42\n",
      "Epoch 43, Train Loss: 17.14, Val Loss: 527.44, Time elapsed [s]: 27.20\n",
      "Epoch 44, Train Loss: 16.32, Val Loss: 526.07, Time elapsed [s]: 27.41\n",
      "Epoch 45, Train Loss: 17.95, Val Loss: 532.45, Time elapsed [s]: 27.56\n",
      "Epoch 46, Train Loss: 18.44, Val Loss: 522.00, Time elapsed [s]: 27.18\n",
      "Epoch 47, Train Loss: 15.98, Val Loss: 532.26, Time elapsed [s]: 27.18\n",
      "Epoch 48, Train Loss: 17.13, Val Loss: 525.78, Time elapsed [s]: 27.17\n",
      "Epoch 49, Train Loss: 19.43, Val Loss: 527.19, Time elapsed [s]: 27.29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "N_EPOCHS= 50\n",
    "save_path_model= './models/Farrow/finetuned/soma_centered/finetuned_scaled_vae_frac%.1f_best_run%i.pt'\n",
    "save_path_losses = './models/Farrow/finetuned/soma_centered/finetuned_scaled_losses_frac%.1f_run%i.npy'\n",
    "save_path_elapsed_time = './models/Farrow/finetuned/soma_centered/finetuned_scaled_elapsed_time_frac%.1f_run%i.npy'\n",
    "# state_dict = torch.load('./models/5_populations/emb32_hid32_lat32_dp0.1_k500_max_frac1.0_scaled_sum_run1_best.pt')\n",
    "\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "for frac in [1., .9, .5, .1, 0.]:\n",
    "    \n",
    "  \n",
    "    runs = range(1,4)\n",
    "        \n",
    "    for run in runs:\n",
    "        \n",
    "        #optimizer\n",
    "        optimizer = optim.Adam(list(model.parameters()) + list(classifier.parameters()), lr=lr)\n",
    "        \n",
    "        if os.path.exists(save_path_model%(frac,run)):\n",
    "            state_dict = torch.load(save_path_model%(frac,run))\n",
    "            \n",
    "            # load model\n",
    "            model.load_state_dict(state_dict['model_state_dict'])\n",
    "            \n",
    "            # overwrite optimizer if the model had been trained already\n",
    "            optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "            classifier.load_state_dict(state_dict['classifier_state_dict'])\n",
    "            losses = np.load(save_path_losses%(frac, run))\n",
    "            elapsed_time = np.load(save_path_elapsed_time%(frac, run))\n",
    "            \n",
    "            last_epoch = state_dict['epoch']\n",
    "            training = list(losses[:last_epoch,:2])\n",
    "            validation = list(losses[:last_epoch,2:])\n",
    "            elapsed_time = elapsed_time[:last_epoch]\n",
    "            elapsed_time = np.hstack((elapsed_time, np.zeros((N_EPOCHS))))\n",
    "            best_test_loss = losses[:,2].min()\n",
    "            \n",
    "        else:\n",
    "            # load pre-trained model\n",
    "            state_dict = torch.load('./models/Farrow/scratch/soma_centered/vae_frac0.0_scaled_best_run%i.pt'%run)\n",
    "            # the first run was the best\n",
    "            model.load_state_dict(state_dict['model_state_dict'])\n",
    "            classifier.apply(init_weights)\n",
    "            best_test_loss = np.infty\n",
    "\n",
    "            losses = np.load('./models/Farrow/scratch/soma_centered/losses_frac0.0_scaled_run%i.npy'%run)\n",
    "            elapsed_time = np.load('./models/Farrow/scratch/soma_centered/elapsed_time_frac0.0_scaled_run%i.npy'%run)\n",
    "            last_epoch = len(elapsed_time)\n",
    "            elapsed_time = np.hstack((elapsed_time, np.zeros((N_EPOCHS))))\n",
    "            training = list(losses[:,:2])\n",
    "            validation = list(losses[:,2:])\n",
    "        \n",
    "        \n",
    "        cross_entropy_loss = torch.nn.CrossEntropyLoss(reduction='sum', ignore_index=-100)\n",
    "        mse_loss = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        for e in range(N_EPOCHS):\n",
    "            start.record()\n",
    "            train_loss, train_class_loss = train(model, classifier, train_iterator, optimizer, \n",
    "                                               calculate_loss,cross_entropy_loss, clip=1, norm_p=None,\n",
    "                                                 class_fraction=frac)\n",
    "            val_loss, val_class_loss = evaluate(model,classifier, val_iterator,\n",
    "                                                 calculate_loss, cross_entropy_loss, norm_p=None)\n",
    "\n",
    "            train_loss /= N_train\n",
    "            train_class_loss /= N_train\n",
    "            val_loss /= N_val\n",
    "            val_class_loss /=N_val\n",
    "            \n",
    "            end.record()\n",
    "\n",
    "            # Waits for everything to finish running\n",
    "            torch.cuda.synchronize()\n",
    "            elapsed_time[e+last_epoch] = start.elapsed_time(end) # milliseconds\n",
    "            \n",
    "            training += [[train_loss,train_class_loss]]\n",
    "            validation += [[val_loss, val_class_loss]]\n",
    "            print(f'Epoch {e}, Train Loss: {train_loss:.2f}, Val Loss: {val_loss:.2f}, Time elapsed [s]: {elapsed_time[e]/1000:.2f}')\n",
    "\n",
    "\n",
    "            if e % 50 == 0 and e > 0:\n",
    "                optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr']/2\n",
    "\n",
    "            if best_test_loss > val_loss:\n",
    "                best_test_loss = val_loss\n",
    "                torch.save({'epoch': e + last_epoch,\n",
    "                            'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'classifier_state_dict': classifier.state_dict()\n",
    "                               },save_path_model%(frac, run))\n",
    "\n",
    "                validation_ = np.array(validation)\n",
    "                training_ = np.array(training)\n",
    "                # [:,0] = training loss, [:,1] = training classification loss \n",
    "                # [:,2] validation loss, [:,3] validation classification loss\n",
    "                losses = np.hstack((training_, validation_))\n",
    "                np.save(save_path_losses%(frac, run),losses)\n",
    "                np.save(save_path_elapsed_time%(frac,run),elapsed_time)\n",
    "        validation = np.array(validation)\n",
    "        training = np.array(training)\n",
    "        losses = np.hstack((training, validation))\n",
    "        np.save(save_path_losses%(frac, run), losses)\n",
    "        np.save(save_path_elapsed_time%(frac,run),elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc4ae3decd0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(validation)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.72294771484375"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed_time.mean()/1000\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
